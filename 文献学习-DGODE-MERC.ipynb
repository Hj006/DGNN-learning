{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b269a09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bc03424",
   "metadata": {},
   "source": [
    "Dynamic Graph Neural Ordinary Differential Equation Network for\n",
    "Multi-modal Emotion Recognition in Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa3684f",
   "metadata": {},
   "source": [
    "摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41292bf",
   "metadata": {},
   "source": [
    "Multimodal emotion recognition in conversation (MERC) :多模态情感识别对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d3c5c",
   "metadata": {},
   "source": [
    "指出现在大多数多模态情感识别方法采用GCN， 存在问题1过拟合，2无法捕捉情感的时序依赖"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b5a13",
   "metadata": {},
   "source": [
    "本文提出的是DGODE，利用自适应混合跳跃（mixhop）机制提升GCN的泛化能力，并通过图ODE演化网络来刻画节点表示随时间的连续动态变化，从而捕捉时序依赖性。还能缓解过平滑问题，从而支持构建更深层次的GCN网络。实际上这个也就是贡献"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba827053",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a0cb0",
   "metadata": {},
   "source": [
    "多模态情感识别对话（MERC）整合多种模态的数据显著提升了情感识别的准确性和广泛应用性，本文发现现有GCN模型通常只包含4层GCN，而随着层数的增加，性能会显著下降。原因可能在于，基础GCN中的信息聚合仅仅是邻域内的简单消息平滑，导致随着层数的堆叠，邻近节点趋于同一数值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1b490",
   "metadata": {},
   "source": [
    "本文模型DGODE在GCN层数增加时，仍能表现出稳定的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331a04d0",
   "metadata": {},
   "source": [
    "2\n",
    "\n",
    "2.1没有什么内容\n",
    "\n",
    "2.2CGNN开发了一种连续消息传递层，以实现节点状态的连续动态建模。与传统的图神经网络（GCN）不同，CGNN不再依赖于固定层数的信息传播，而是通过求解常微分方程，使节点之间的信息能够连续传播。CGNN还引入了重启分布，在信息传播过程中及时将节点状态“重置”为初始状态，从而避免了过平滑问题。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551bde15",
   "metadata": {},
   "source": [
    "**3.1 图神经网络（Graph Neural Networks）**\n",
    "\n",
    "给定一个图 $G = (V, E)$， $V$ 是节点的集合，$E$ 是边的集合。\n",
    "\n",
    "每个节点 $v \\in V$ 构成节点特征矩阵 $X \\in \\mathbb{R}^{|V| \\times d}$，其中 $d$ 表示特征的维度。$X$ 的每一行对应一个节点的特征表示。\n",
    "\n",
    "使用二值邻接矩阵 $A \\in \\mathbb{R}^{|V| \\times |V|}$ 来表示节点 $i$ 与节点 $j$ 之间的连接关系。如果 $a_{ij} = 1$，则表示节点 $i$ 和节点 $j$ 之间有一条边；如果 $a_{ij} = 0$，则表示两者之间没有连接。\n",
    "\n",
    "目标是学习一个节点表示矩阵 $H$，该矩阵能够捕捉到图中节点的结构信息和特征信息。\n",
    "\n",
    "对称归一化邻接矩阵：\n",
    "\n",
    "$$\n",
    "\\hat{A} = \\alpha \\left( I + D^{-\\frac{1}{2}} A D^{-\\frac{1}{2}} \\right)\n",
    "$$\n",
    "\n",
    "其中 $\\alpha$ 是一个超参数。\n",
    "\n",
    "---\n",
    "\n",
    "**3.2 神经常微分方程（Neural Ordinary Differential Equation, Neural ODE）**\n",
    "\n",
    "一个输入数据 $x(t)$，其演化过程可用如下ODE形式描述：\n",
    "\n",
    "$$\n",
    "\\frac{dx(t)}{dt} = f(x(t), t, \\theta)\n",
    "$$\n",
    "\n",
    "其中，$x(t)$ 表示时刻 $t$ 的隐藏状态，$f$ 是带参数 $\\theta$ 的神经网络函数。\n",
    "\n",
    "---\n",
    "\n",
    "**3.3 多模态特征提取**\n",
    "\n",
    "* **词嵌入（Word Embedding）：** 按照以往研究（Chudasama 等，2022；Li 等，2022b），本文采用 RoBERTa（Liu，2019）来获得文本的上下文嵌入表示。\n",
    "* **视觉与音频特征提取（Visual and Audio Feature Extraction）：** 参考以往工作（Ma 等，2023；Lian 等，2021），我们选用了 DenseNet（Huang 等，2017）和 openSMILE（Eyben 等，2010）作为视频和音频的特征提取工具。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d784327b",
   "metadata": {},
   "source": [
    "输入：一段包含多轮对话的对话序列，每轮有说话人和三种模态（音频、视频、文本）特征。\n",
    "\n",
    "输出：每一句话对应的情感标签。\n",
    "\n",
    "任务难点：需要同时利用三种数据模态的信息，还要考虑对话中多说话人、时序、上下文等复杂因素。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe956b5",
   "metadata": {},
   "source": [
    "4.1 Modality Encoding\n",
    "\n",
    "建模时不仅要有每句话的内容、音频、视频等信息，还把说话人身份和上下文语境信息编码进去。\n",
    "\n",
    "每个说话人用一个独特的one-hot向量 $p_i$ 表示。用一个可学习的权重矩阵 $W_p$ 对 $p_i$ 做线性变换，得到说话人嵌入向量 $P_i = W_p p_i$。\n",
    "\n",
    "对于文本、音频、视频三种模态，分别用GRU对序列数据进行建模，抓取其时序上下文特征。\n",
    "\n",
    "即对每一轮发言的每种模态输入，GRU都会考虑“这句话前后的内容”，提取时间相关性和上下文依赖信息。\n",
    "\n",
    "公式写作：$\\hat{v_m^i} = \\overleftrightarrow{GRU}(v_m^i, c_m^i(+,-)), m \\in \\{a, v, f\\}$\n",
    "\n",
    "  其中 $v_m^i$ 是第i轮的模态输入，$c_m^i(+,-)$ 是GRU的cell状态（带正反向）。\n",
    "  \n",
    "  m = a（audio），v（visual），f（feature or fused, 实际可理解为文本）。\n",
    "\n",
    "得到每种模态的上下文特征（GRU输出），再加上当前说话人的嵌入向量，形成融合了说话人身份和上下文的单模态表示：\n",
    "\n",
    "  * $h_m^i = c_m^i + S_i, m \\in \\{t, a, v\\}$\n",
    "  * 其中 $S_i$ 就是上面算出来的说话人嵌入，$c_m^i$ 是模态特征。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b80a0",
   "metadata": {},
   "source": [
    "**传统GCN的局限**：\n",
    "  传统GCN**每一层只能聚合“一阶邻居”**（即相连的直接邻居），即使堆叠多层也往往聚合能力有限，且容易出现“过平滑”（所有节点特征越来越相似）。\n",
    "\n",
    "\n",
    "*MixHop思想：多阶邻居聚合\n",
    "\n",
    "\n",
    "MixHop就是**让每一层可以同时聚合多阶邻居**的信息，比如一阶、二阶、三阶……甚至更远的邻居节点。通俗地说，MixHop可以“多跳”收集信息，而不是只看最邻近的节点。\n",
    "\n",
    "文中强调“自适应”，即模型可以自学习/自选择每阶邻居聚合时的权重或方式，更灵活地调整信息融合策略。\n",
    "\n",
    "**公式**\n",
    "\n",
    "$$\n",
    "H_{n+1} = \\sum_{n=1}^{N} \\hat{A}^{n} H_n W + H_0\n",
    "$$\n",
    "\n",
    "* $\\hat{A}$：归一化的邻接矩阵\n",
    "* $\\hat{A}^n$：表示n阶邻居的信息扩散（比如$\\hat{A}^2$就是二阶邻居）\n",
    "* $H_n$：第n层的节点特征\n",
    "* $W$：可学习的权重参数（对每阶聚合线性变换）\n",
    "* $H_0$：原始节点特征（残差项，类似ResNet的设计，防止信息丢失）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19a8990",
   "metadata": {},
   "source": [
    "4.3 Temporal Graph ODE\n",
    "\n",
    "MixHop GCN虽然能够捕捉多阶邻居关系，但它本质还是**离散的层级传播**，**无法模拟节点表示随时间连续变化的动态过程**。而在多模态情感识别中，情绪是随时间动态演变的，单纯的离散GCN难以捕捉“情感随时间流动的连续依赖”。\n",
    "\n",
    "\n",
    " **把GCN的信息传播过程，从“离散层级”推广为“连续动态演化”**，即用常微分方程（ODE）来建模节点状态随时间的连续变化。这样，模型就可以捕捉情绪/节点特征随时间推移的细腻变化过程。\n",
    "\n",
    "1. **离散到连续的转化**\n",
    "\n",
    "   * 之前的GCN聚合公式是离散的：\n",
    "\n",
    "     $$\n",
    "     H_{n+1} = \\sum_{n=1}^{N} \\hat{A}^{n} H_n W + H_0\n",
    "     $$\n",
    "   * 现在把它看作是“积分的Riemann和”。本质上，把离散相加看作积分的近似，从而推广到连续时间域。\n",
    "\n",
    "2. **引入ODE建模传播过程**\n",
    "\n",
    "   * 推导得出，节点特征 $H(t)$ 的连续动态演化可以表示为一个ODE（常微分方程）：\n",
    "\n",
    "     $$\n",
    "     \\frac{dH(t)}{dt} = \\frac{1}{N}\\sum_{n=1}^{N} \\Big( \\ln\\hat{A} H(t) + H(t)\\ln W + E \\Big)\n",
    "     $$\n",
    "\n",
    "     * $H(t)$：时刻t的节点特征\n",
    "     * $\\ln\\hat{A}$：对归一化邻接矩阵做对数，理论上是为了便于连续化传播建模\n",
    "     * $W$：权重矩阵\n",
    "     * $E$：初始状态相关项\n",
    "\n",
    "   * 这样建模后，信息传播就不是单步单层，而是**时间上连续地演化，能够模拟“情感随时间流转”的细节**。\n",
    "\n",
    "3. **解析解与数值求解**\n",
    "\n",
    "   * ODE在某些情况下的解析解（公式8），不过实际用法里更常见的是用\\*\\*ODE求解器（ODESolver）\\*\\*在数值上逐步模拟节点特征的变化过程：\n",
    "\n",
    "     $$\n",
    "     H(t) = ODESolver\\left(\\frac{dH(t)}{dt}, H_0, t\\right)\n",
    "     $$\n",
    "\n",
    "     * $H_0$：初始节点特征\n",
    "     * ODESolver可以选用如Euler、RK4等常用数值解法"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
